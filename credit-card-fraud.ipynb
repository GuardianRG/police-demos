{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "#%matplotlib inline\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/creditcardmin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape\n",
    "print('This data frame has {} rows and {} columns.'.format(df.shape[0], df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#peek at data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('datasets/creditcardmin.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerical summary -> only non-anonymized columns of interest\n",
    "pd.set_option('precision', 3)\n",
    "df.loc[:, ['Time', 'Amount']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizations of time and amount\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Distribution of Time Feature')\n",
    "sns.distplot(df.Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Distribution of Monetary Value Feature')\n",
    "sns.distplot(df.Amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around 88 dollars is the mean of all credit card transactions in this data set. The biggest transaction had a monetary value of around 25,691 dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fraud vs. normal transactions \n",
    "counts = df.Class.value_counts()\n",
    "normal = counts[0]\n",
    "fraudulent = counts[1]\n",
    "perc_normal = (normal/(normal+fraudulent))*100\n",
    "perc_fraudulent = (fraudulent/(normal+fraudulent))*100\n",
    "print('There were {} non-fraudulent transactions ({:.3f}%) and {} fraudulent transactions ({:.3f}%).'.format(normal, perc_normal, fraudulent, perc_fraudulent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x=counts.index, y=counts)\n",
    "plt.title('Count of Fraudulent vs. Non-Fraudulent Transactions')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Class (0:Non-Fraudulent, 1:Fraudulent)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap\n",
    "corr = df.corr()\n",
    "plt.figure(figsize=(12,10))\n",
    "heat = sns.heatmap(data=corr)\n",
    "plt.title('Heatmap of Correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skewness\n",
    "skew_ = df.skew()\n",
    "skew_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling Amount and Time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler2 = StandardScaler()\n",
    "#scaling time\n",
    "scaled_time = scaler.fit_transform(df[['Time']])\n",
    "flat_list1 = [item for sublist in scaled_time.tolist() for item in sublist]\n",
    "scaled_time = pd.Series(flat_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the amount column\n",
    "scaled_amount = scaler2.fit_transform(df[['Amount']])\n",
    "flat_list2 = [item for sublist in scaled_amount.tolist() for item in sublist]\n",
    "scaled_amount = pd.Series(flat_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenating newly created columns w original df\n",
    "df = pd.concat([df, scaled_amount.rename('scaled_amount'), scaled_time.rename('scaled_time')], axis=1)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping old amount and time columns\n",
    "df.drop(['Amount', 'Time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting Data into Train and Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual train test split using numpy's random.rand\n",
    "mask = np.random.rand(len(df)) < 0.9\n",
    "train = df[mask]\n",
    "test = df[~mask]\n",
    "print('Train Shape: {}\\nTest Shape: {}'.format(train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a subsample data set with balanced class distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many random samples from normal transactions do we need?\n",
    "no_of_frauds = train.Class.value_counts()[1]\n",
    "print('There are {} fraudulent transactions in the train data.'.format(no_of_frauds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly selecting 442 random non-fraudulent transactions\n",
    "non_fraud = train[train['Class'] == 0]\n",
    "fraud = train[train['Class'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = non_fraud.sample(no_of_frauds)\n",
    "selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenating both into a subsample data set with equal class distribution\n",
    "selected.reset_index(drop=True, inplace=True)\n",
    "fraud.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample = pd.concat([selected, fraud])\n",
    "len(subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling our data set\n",
    "subsample = subsample.sample(frac=1).reset_index(drop=True)\n",
    "subsample.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_counts = subsample.Class.value_counts()\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x=new_counts.index, y=new_counts)\n",
    "plt.title('Count of Fraudulent vs. Non-Fraudulent Transactions In Subsample')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Class (0:Non-Fraudulent, 1:Fraudulent)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking a look at correlations once more\n",
    "corr = subsample.corr()\n",
    "corr = corr[['Class']]\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#negative correlations smaller than -0.5\n",
    "corr[corr.Class < -0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#positive correlations greater than 0.5\n",
    "corr[corr.Class > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the features w high negative correlation\n",
    "f, axes = plt.subplots(nrows=2, ncols=4, figsize=(26,16))\n",
    "\n",
    "f.suptitle('Features With High Negative Correlation', size=35)\n",
    "sns.boxplot(x=\"Class\", y=\"V3\", data=subsample, ax=axes[0,0])\n",
    "sns.boxplot(x=\"Class\", y=\"V9\", data=subsample, ax=axes[0,1])\n",
    "sns.boxplot(x=\"Class\", y=\"V10\", data=subsample, ax=axes[0,2])\n",
    "sns.boxplot(x=\"Class\", y=\"V12\", data=subsample, ax=axes[0,3])\n",
    "sns.boxplot(x=\"Class\", y=\"V14\", data=subsample, ax=axes[1,0])\n",
    "sns.boxplot(x=\"Class\", y=\"V16\", data=subsample, ax=axes[1,1])\n",
    "sns.boxplot(x=\"Class\", y=\"V17\", data=subsample, ax=axes[1,2])\n",
    "f.delaxes(axes[1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the features w high positive correlation\n",
    "f, axes = plt.subplots(nrows=1, ncols=2, figsize=(18,9))\n",
    "\n",
    "f.suptitle('Features With High Positive Correlation', size=20)\n",
    "sns.boxplot(x=\"Class\", y=\"V4\", data=subsample, ax=axes[0])\n",
    "sns.boxplot(x=\"Class\", y=\"V11\", data=subsample, ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extreme Outlier Removal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only removing extreme outliers\n",
    "Q1 = subsample.quantile(0.25)\n",
    "Q3 = subsample.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "df2 = subsample[~((subsample < (Q1 - 2.5 * IQR)) |(subsample > (Q3 + 2.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_after = len(df2)\n",
    "len_before = len(subsample)\n",
    "len_difference = len(subsample) - len(df2)\n",
    "print('We reduced our data size from {} transactions by {} transactions to {} transactions.'.format(len_before, len_difference, len_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dimensionality Reduction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "X = df2.drop('Class', axis=1)\n",
    "y = df2['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t-SNE\n",
    "X_reduced_tsne = TSNE(n_components=2, random_state=42).fit_transform(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE scatter plot\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "f, ax = plt.subplots(figsize=(24,16))\n",
    "\n",
    "\n",
    "blue_patch = mpatches.Patch(color='#0A0AFF', label='No Fraud')\n",
    "red_patch = mpatches.Patch(color='#AF0000', label='Fraud')\n",
    "\n",
    "ax.scatter(X_reduced_tsne[:,0], X_reduced_tsne[:,1], c=(y == 0), cmap='coolwarm', label='No Fraud', linewidths=2)\n",
    "ax.scatter(X_reduced_tsne[:,0], X_reduced_tsne[:,1], c=(y == 1), cmap='coolwarm', label='Fraud', linewidths=2)\n",
    "ax.set_title('t-SNE', fontsize=14)\n",
    "\n",
    "ax.grid(True)\n",
    "\n",
    "ax.legend(handles=[blue_patch, red_patch])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Algorithms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_validation = X_test.values\n",
    "y_train = y_train.values\n",
    "y_validation = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_shapes:\\n', 'X_train:', 'X_validation:\\n', X_train.shape, X_validation.shape, '\\n')\n",
    "print('Y_shapes:\\n', 'Y_train:', 'Y_validation:\\n', y_train.shape, y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Spot-Checking Algorithms\n",
    "\n",
    "models = []\n",
    "\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('SVM', SVC()))\n",
    "#models.append(('XGB', XGBClassifier()))\n",
    "#models.append(('RF', RandomForestClassifier()))\n",
    "\n",
    "#testing models\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=42)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='roc_auc')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: %f (%f)' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression()\n",
    "temp = logisticRegr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(temp.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare Algorithms\n",
    "\n",
    "fig = plt.figure(figsize=(12,10))\n",
    "plt.title('Comparison of Classification Algorithms')\n",
    "plt.xlabel('Algorithm')\n",
    "plt.ylabel('ROC-AUC Score')\n",
    "plt.boxplot(results)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have trained a classification algorithm for this dataset, that lets us classify fraudulent transactions with high accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p37env",
   "language": "python",
   "name": "p37env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
